{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimization of azimuth and tilt angles for given Tx positions to maximize coverage in a given area.\n",
    "\n",
    "You can just run all cells, or run all until \"Run Optimization - Run Optimization with Gradient Descent and Random Search\" and select parameters there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1' \n",
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as  plt\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from typing import Sequence\n",
    "from math import ceil\n",
    "\n",
    "from lib.pl_datamodule import LitRM_directional\n",
    "from lib.pl_lightningmodule import LitModelDict\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samplesv2(\n",
    "        tensor_dict :   dict[str, tuple[torch.Tensor, torch.Tensor] | torch.Tensor],\n",
    "        batch_ids : Sequence | None = None,\n",
    "        filename : str | Path | None  = None,\n",
    "        titles : Sequence[str] | str | None  = None,\n",
    "        vmin : float | None = None,\n",
    "        vmax : float | None = None,\n",
    "    ) -> list:\n",
    "    '''\n",
    "    Generates and potentially saves a figure displaying several tensors.\n",
    "    Args:\n",
    "        tensor_dict     -   dict, keys are names and values are either tensors to be displayed or tuple of these plus coordinates in another tensor \n",
    "                            tensors to be displayed must have dim B x C x H x W (display each channel separately) or B x H x W\n",
    "        batch_ids       -   ids of samples to be displayed, if None, we display all\n",
    "        filename        -   give filename to save the fig\n",
    "        title           -   title of the fig\n",
    "        cut             -   cut all tensors to range [0,1] in imshow\n",
    "    '''\n",
    "    ### generate a list of figures, one for each batch_id\n",
    "    fig_list = []\n",
    "    if batch_ids is None:\n",
    "        first = list(tensor_dict.values())[0]\n",
    "        if isinstance(first, tuple):\n",
    "            batch_ids = range(first[0].shape[0])\n",
    "        else:\n",
    "            batch_ids = range(first.shape[0])\n",
    "    if isinstance(titles, str):\n",
    "        titles = [titles for b in batch_ids]\n",
    "    for batch_id in batch_ids:\n",
    "        ### generate a list of tensors to be displayed together with title and maybe coordinates to be scattered, this is needed to plan the size of the figure\n",
    "        display_list = []\n",
    "        for k, v in tensor_dict.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                t_curr = v[batch_id,:].detach().cpu()\n",
    "                if t_curr.ndim == 2:\n",
    "                    display_list.append((k, t_curr, None))\n",
    "                elif t_curr.ndim == 3:\n",
    "                    display_list.extend([(f'{k} {c}', t_curr[c,:], None) for c in range(t_curr.shape[0])])\n",
    "                else:\n",
    "                    raise ValueError(f'got shape {t_curr.shape} for tensor {k}')\n",
    "            elif isinstance(v, (tuple, list)):\n",
    "                assert len(v)==2, f'got tensor/coords {v}'\n",
    "                t_curr, coords_curr = v[0][batch_id,:].detach().cpu(), v[1][batch_id,:].detach().cpu()\n",
    "                if t_curr.ndim == 2:\n",
    "                    display_list.append((k, t_curr, coords_curr))\n",
    "                elif t_curr.ndim == 3:\n",
    "                    if t_curr.shape[0] == coords_curr.shape[0]:\n",
    "                        display_list.extend([(f'{k} {c}', t_curr[c,:], coords_curr[c,:]) for c in range(t_curr.shape[0])])\n",
    "                    else:\n",
    "                        ### plot all coordinates on all maps\n",
    "                        if coords_curr.ndim == 1:\n",
    "                            display_list.extend([(f'{k} {c}', t_curr[c,:], coords_curr) for c in range(t_curr.shape[0])])\n",
    "                        else:\n",
    "                            display_list.extend([(f'{k} {c}', t_curr[c,:], torch.transpose(coords_curr, -1,-2)) for c in range(t_curr.shape[0])])\n",
    "                else:\n",
    "                    raise ValueError(f'got shape {t_curr.shape} for tensor {k}')\n",
    "        cols = 5\n",
    "        rows = int(ceil(len(display_list) / 5))\n",
    "        fig = plt.figure(figsize=(4*cols, 3*rows))\n",
    "        if titles is not None:\n",
    "            fig.suptitle(titles[batch_id])\n",
    "        for idf, t in  enumerate(display_list):\n",
    "            fig.add_subplot(rows, cols, idf + 1)\n",
    "            plt.imshow(t[1], vmax=vmax, vmin=vmin)\n",
    "            plt.colorbar()\n",
    "            plt.title(t[0])\n",
    "            plt.tick_params(\n",
    "                axis='both',      \n",
    "                which='both',     \n",
    "                bottom=False,     \n",
    "                top=False,        \n",
    "                labelbottom=False,\n",
    "                labelleft=False,\n",
    "                left=False, \n",
    "                right=False\n",
    "                ) \n",
    "            if t[2] is not None:\n",
    "                plt.scatter(t[2][1], t[2][0], c='r', s=10)\n",
    "        if filename is not None:\n",
    "            plt.savefig(f'{filename}_{batch_id}.png')\n",
    "        fig_list.append(fig)\n",
    "    return fig_list\n",
    "\n",
    "def load_model_from_dir(previous_model_dir : Path | str):\n",
    "    '''\n",
    "    Load a trained model from a directory by automatically combining the checkpoint and config. Note that when using the CLI, we need to use the config\n",
    "    '''\n",
    "    import yaml\n",
    "    sub_dir = list(Path(previous_model_dir).iterdir())\n",
    "    if not len(sub_dir)==1:\n",
    "        sub_dir = Path(previous_model_dir)\n",
    "    else:\n",
    "        sub_dir = sub_dir[0]\n",
    "    ckpt1 = list((sub_dir / 'checkpoints').glob('*loss*.ckpt'))\n",
    "    assert len(ckpt1) == 1, f'checkpoint for model1 ({previous_model_dir}) not (uniquely) determined, found {ckpt1}'\n",
    "    ckpt1 = ckpt1[0]\n",
    "    config = sub_dir / 'config.yaml'\n",
    "    assert config.is_file(), f'config for model1 ({previous_model_dir}) not existing/not a file'\n",
    "    with open(config, 'r') as f:\n",
    "        params = yaml.safe_load(f)\n",
    "    model1_class = LitModelDict[params['model']['class_path'].split('.')[-1]]\n",
    "    previous = model1_class.load_from_checkpoint(ckpt1)\n",
    "    print(f'loaded {model1_class} from {ckpt1} using {config}')\n",
    "    return previous, params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate network inputs\n",
    "- Define network inputs as differentiable functions of Tx azimuth and elevation angle, as far as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antenna patters\n",
    "- The antenna pattern inputs are generated by looking up the gain corresponding to combinations of azimuth and tilt in a file so far, we approximate them as a function of the coordinates and angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load and visualize an example antenna pattern, of the widest antenna used in the dataset. This one has a HPBW of 90° and a FNBW of 120°\n",
    "patt = np.load('./dataset/antenna_patterns/pattern_8.npy')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(patt)\n",
    "plt.xlabel('phi [deg]')\n",
    "plt.ylabel('theta [deg]')\n",
    "plt.colorbar()\n",
    "plt.title('Antenna pattern in 2D')\n",
    "\n",
    "### The pattern is symmetric, so we can flatten it to a 1D pattern \n",
    "patt_flat = np.zeros((360))\n",
    "patt_flat[:180] = patt[90, 180:360]\n",
    "patt_flat[180:] = patt[90, :180]\n",
    "\n",
    "### in 2D\n",
    "plt.figure(figsize=(10, 5))\n",
    "k = 10\n",
    "r_angles = torch.arange(-torch.pi, torch.pi, step=2*torch.pi/360)\n",
    "fnbw = 120 / 360 * 2 * torch.pi\n",
    "\n",
    "for k in [1, 5, 10]:\n",
    "        gain_floor = 1 / (1 + torch.exp(-2 * k * (-r_angles**2 + fnbw /2 ))) * 250 - 250\n",
    "        plt.plot(r_angles, gain_floor, label=f'approximation {k=}')\n",
    "\n",
    "plt.plot(r_angles, patt_flat , label='original', c='black')\n",
    "plt.xlabel('phi [rad]')\n",
    "plt.ylabel('gain [dB]')\n",
    "plt.legend()\n",
    "plt.title('Antenna pattern along theta=0')\n",
    "\n",
    "phis = torch.arange(0, 2*np.pi, step=2*np.pi/360).unsqueeze(0)\n",
    "thetas = torch.arange(0, np.pi, step=2*np.pi/360).unsqueeze(1)\n",
    "r_angles = torch.sqrt((thetas - torch.pi/2)**2 + torch.minimum(phis, 2*torch.pi - phis)**2)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(1 / (1 + torch.exp(-2 * k * (-r_angles**2 + fnbw /2 ))) * 250 - 250)\n",
    "plt.colorbar()\n",
    "plt.xlabel('phi [deg]')\n",
    "plt.ylabel('theta [deg]')\n",
    "plt.title(f'Approximated antenna pattern in 2D ({k=})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate inputs using a nn.Module\n",
    "- Generate antenna pattern as above and all other inputs, as far as possible as differentiable functions of Tx azimuth and elevation, as input for trained CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translate_coords_angles_img(torch.nn.Module):\n",
    "    '''translate tx coords and angles, ndsms in a smooth differentiable way into network inputs, as far as possible'''\n",
    "    def __init__(self, \n",
    "        # hpbw = 90,\n",
    "        fnbw = 120,\n",
    "        x_shift = 0,\n",
    "        k_logistic = 10,\n",
    "        x_dim = 256,\n",
    "        y_dim = 256,\n",
    "        tx_height = 2,\n",
    "        img = True,\n",
    "        img_rgb = False,\n",
    "        ndsm_all = False,\n",
    "        tx_one_hot = True,\n",
    "        azimuth = False,\n",
    "        dist2d = False,\n",
    "        coords_ga = False,\n",
    "        z_max = 32,\n",
    "        z_min_tx = 6,\n",
    "        eps_sqrt = 0.0001,\n",
    "        gain_approx = 'logistic',\n",
    "        device = torch.device('cuda'),\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # self.hpbw = hpbw / 360 * 2 * torch.pi\n",
    "        self.fnbw = fnbw / 360 * 2 * torch.pi\n",
    "        self.x_shift = x_shift / 360 * 2 * torch.pi\n",
    "        self.k_logistic = k_logistic\n",
    "\n",
    "        xy_range = torch.arange(256, dtype=torch.float32, device=device)\n",
    "        self.xc_base = torch.nn.Parameter(torch.repeat_interleave(xy_range.reshape((-1, 1)), repeats=x_dim, dim=1), requires_grad=False)\n",
    "        self.yc_base = torch.nn.Parameter(torch.repeat_interleave(xy_range.reshape((1, -1)), repeats=y_dim, dim=0), requires_grad=False)\n",
    "        self.tx_height = torch.nn.Parameter(torch.tensor([tx_height], device=device), requires_grad=False)\n",
    "        self.z_max = torch.nn.Parameter(torch.tensor([z_max], device=device), requires_grad=False)\n",
    "        self.min_height = torch.nn.Parameter(torch.tensor([z_min_tx], device=device), requires_grad=False)\n",
    "\n",
    "        self.img = img\n",
    "        self.img_rgb = img_rgb\n",
    "        self.ndsm_all = ndsm_all\n",
    "        self.tx_one_hot = tx_one_hot\n",
    "        self.azimuth = azimuth\n",
    "        self.dist2d = dist2d\n",
    "        self.coords_ga = coords_ga        \n",
    "        self.eps_sqrt = eps_sqrt\n",
    "        self.gain_approx = gain_approx\n",
    "\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, coords : torch.Tensor, angles : torch.Tensor, inputs : torch.Tensor):\n",
    "        ### assuming we have a batch dimension...\n",
    "        ### split up inputs, we expect them to always contain ndsm plus RGBIR image, nothing else\n",
    "\n",
    "        assert inputs.shape[1] == 5, f'inputs shape: {inputs.shape}'\n",
    "        ndsm_all = inputs[:,:1,:,:] * self.z_max\n",
    "        img = inputs[:,1:,:,:]\n",
    "\n",
    "        xt, yt, tx_phi, tx_theta = coords[:,0].view((-1,1,1,1)), coords[:,1].view((-1,1,1,1)), angles[:,0].view((-1,1,1,1)), angles[:,1].view((-1,1,1,1))\n",
    "        zt = torch.maximum(ndsm_all[torch.arange(ndsm_all.shape[0]),:,xt.type(torch.int32).squeeze(), yt.type(torch.int32).squeeze()].view((-1,1,1,1)) + self.tx_height, self.min_height)\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        if self.tx_one_hot:\n",
    "            tx_one_hot_tens = torch.zeros_like(ndsm_all)\n",
    "            tx_one_hot_tens[torch.arange(ndsm_all.shape[0]), 0, xt.type(torch.int32).squeeze(), yt.type(torch.int32).squeeze()] = zt.squeeze() / self.z_max\n",
    "            outputs.append(tx_one_hot_tens)\n",
    "        if self.ndsm_all:\n",
    "            outputs.append(ndsm_all / self.z_max)\n",
    "        \n",
    "        ### build cylindrical coordinate system\n",
    "        xc, yc = self.xc_base - xt, self.yc_base - yt\n",
    "        phi = torch.arctan2(yc, xc)\n",
    "        ### rotate\n",
    "        tx_phi = tx_phi % (2*np.pi)\n",
    "        phi = phi - tx_phi\n",
    "        ### correct\n",
    "        phi = torch.where(phi < -1 * torch.pi, 2 * torch.pi + phi, phi)\n",
    "        phi = torch.where(phi > torch.pi, phi - 2 * torch.pi, phi)\n",
    "\n",
    "        r = torch.sqrt(xc**2 + yc**2 + self.eps_sqrt)\n",
    "\n",
    "        if self.dist2d:\n",
    "            outputs.append(r / (np.sqrt(2) * 255))\n",
    "        if self.coords_ga:\n",
    "            outputs.extend([\n",
    "                xt * torch.ones((1, 1, 256, 256), device=self.device) / 256,\n",
    "                yt * torch.ones((1, 1, 256, 256), device=self.device) / 256, \n",
    "                zt * torch.ones((1, 1, 256, 256), device=self.device) / self.z_max, \n",
    "                torch.ones((xt.shape[0], 1, 1, 1), device=self.device) * self.xc_base.unsqueeze(0) / 256, \n",
    "                torch.ones((xt.shape[0], 1, 1, 1), device=self.device) * self.yc_base.unsqueeze(0) / 256\n",
    "            ])\n",
    "\n",
    "        ### antenna gain map\n",
    "        if self.fnbw < 2 * np.pi:\n",
    "            tx_theta = torch.clip(tx_theta, 0, np.pi)\n",
    "            theta_floor = torch.arccos(-zt / torch.sqrt(xc**2 + yc**2 + zt**2)) - tx_theta\n",
    "            r_angles = torch.sqrt(phi**2 + theta_floor**2 + self.eps_sqrt)\n",
    "            if self.gain_approx == 'logistic':\n",
    "                gain_floor = torch.min(1 / (1 + torch.exp(-2 * self.k_logistic * (-r_angles + self.fnbw /2 + self.x_shift))), 1 / (1 + torch.exp(-2 * self.k_logistic * (r_angles + self.fnbw /2 + self.x_shift))))\n",
    "            elif self.gain_approx == 'gauss':\n",
    "                gain_floor = torch.exp(-1 * self.k_logistic * r_angles**2)\n",
    "            outputs.append(gain_floor)\n",
    "\n",
    "        if self.azimuth:\n",
    "            outputs.append(phi)\n",
    "        if self.img:\n",
    "            outputs.append(img)\n",
    "        if self.img_rgb:\n",
    "            outputs.append(img[:,:3,:,:])\n",
    "        \n",
    "        return torch.cat(outputs, dim=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to load Tx positions and angles from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_ant_dir = Path('./dataset/tx_antennas/')\n",
    "tx_ant_file_name = '{}_{}_{}_txparams.json'\n",
    "\n",
    "def get_coords_angles(sample_id, batch_id, tx_ant_dir, tx_ant_file_name, coords_requires_grad=False, angles_requires_grad=True, dtype=torch.float32, tx_ids=None, device=torch.device('cuda')):\n",
    "    '''same as above, but we also retrieve the angles for each location and return the average to obtain a starting point for the optimization'''\n",
    "    with open(tx_ant_dir / tx_ant_file_name.format(*[sample_id[i][batch_id] for i in range(3)]), 'r') as f:\n",
    "        tx_ant_all = json.load(f)\n",
    "    ca = {}\n",
    "    for txparams in tx_ant_all.values():\n",
    "        coords  = tuple(txparams['tx_coords'][:2])\n",
    "        if coords in ca.keys():\n",
    "            ca[coords].append([txparams['phi'], txparams['theta']])\n",
    "        else:\n",
    "            ca[coords] = [[txparams['phi'], txparams['theta']]]\n",
    "    try:\n",
    "        if tx_ids is not None:\n",
    "            coords_tensor = torch.tensor([k for i, k in enumerate(ca.keys()) if i in tx_ids], device=device, dtype=dtype, requires_grad=coords_requires_grad)\n",
    "            angles_tensor = torch.tensor([np.mean(np.array(v), axis=0) for i, v in enumerate(ca.values()) if i in tx_ids], device=device, dtype=dtype, requires_grad=angles_requires_grad)\n",
    "        else:\n",
    "            coords_tensor = torch.tensor(list(ca.keys()), device=device, dtype=dtype, requires_grad=coords_requires_grad)\n",
    "            angles_tensor = torch.tensor([np.mean(np.array(v), axis=0) for v in ca.values()], device=device, dtype=dtype, requires_grad=angles_requires_grad)\n",
    "    except RuntimeError as e:\n",
    "        print(f'Error: {e}\\n {ca.keys()=}, {ca.values()=}')\n",
    "\n",
    "    return coords_tensor, angles_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained model to generate the RM predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load a trained model from a checkpoint, compare its outputs with original inputs and the generated ones\n",
    "ckpt_dir = './ckpts_paper/img/LitUNetDCN_LitRM_directional'\n",
    "ckpt_dir = './ckpts_paper/img_ndsm_coords/LitUNetDCN_LitRM_directional'\n",
    "net, params = load_model_from_dir(ckpt_dir)\n",
    "net = net.to(device).eval()\n",
    "print([k for k,v in params['data']['init_args'].items() if v is True])\n",
    "\n",
    "\n",
    "eps_sqrt = 0.001\n",
    "k_logistic = 10\n",
    "tr = translate_coords_angles_img(**params['data']['init_args'], eps_sqrt=eps_sqrt, k_logistic=k_logistic, old_azimuth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the loaded model and the generated inputs\n",
    "- Load a few samples, show the inputs and targets and also replicate the inputs by our method above and generate outputs from the network again.\n",
    "- The approximated antenna pattern could still be improved to match the original one closer. But this is not really the point for us here, we just want to see that the networks produce reasonable, realistic radio maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_min = 3\n",
    "i_max = 3\n",
    "batch_size = 32\n",
    "\n",
    "### load sample ids, quick test\n",
    "id_file = './dataset/sample_ids_antennas.json'\n",
    "\n",
    "with open(id_file, 'r') as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "map_ids = sample_data['map_ids']\n",
    "sample_ids = sample_data['sample_ids']\n",
    "\n",
    "## test for a few samples from the dataset whether inputs agree (azimuth, dist2d and gain floor)\n",
    "dm_net = LitRM_directional(**{**params['data']['init_args'], 'augmentation' : False, 'batch_size' : batch_size, 'shuffle' : False})\n",
    "dm_net.setup('test')\n",
    "dm_net.test_set.get_ids = True\n",
    "loader_net = dm_net.test_dataloader()\n",
    "\n",
    "dm_tr = LitRM_directional(ndsm_all=True, img=True, tx_one_hot=False, ndsms=False, ant_gain_floor=False, ant_gain_top=False, augmentation=False, batch_size=batch_size, shuffle=False)\n",
    "dm_tr.setup()\n",
    "dm_tr.setup('test')\n",
    "dm_tr.test_set.get_ids = True\n",
    "loader_tr = dm_tr.test_dataloader()\n",
    "\n",
    "\n",
    "    \n",
    "for i, ((inp_net, targ_net, _, sample_id_net), (inp_tr, targ_tr, _, sample_id_tr)) in enumerate(zip(loader_net, loader_tr)):\n",
    "    if i < i_min:\n",
    "        continue\n",
    "    if i > i_max:   \n",
    "        break\n",
    "    with torch.no_grad():\n",
    "        assert torch.all(targ_net==targ_tr) and sample_id_net==sample_id_tr\n",
    "        samples_to_show = []\n",
    "        ### for each sample in the batch, load the txparams, then create the inputs for the network in one batch together\n",
    "        coords = torch.zeros((inp_net.shape[0], 2), device=device)\n",
    "        angles = torch.zeros((inp_net.shape[0], 2), device=device)\n",
    "        titles = []\n",
    "        for k in range(inp_net.shape[0]):\n",
    "            with open(tx_ant_dir / tx_ant_file_name.format(*[sample_id_net[i][k] for i in range(3)]), 'r') as f:\n",
    "                tx_ant = json.load(f)[sample_id_net[3][k]]\n",
    "            if tx_ant['antenna']==8:\n",
    "                samples_to_show.append(k)\n",
    "            \n",
    "            coords[k,:] = torch.tensor(tx_ant['tx_coords'][:2]) \n",
    "            angles[k,:] = torch.tensor([tx_ant['phi'], tx_ant['theta']])\n",
    "            titles.append(f'antenna {tx_ant[\"antenna\"]} {\"_\".join([sample_id_net[i][k] for i in range(3)])}')\n",
    "            if len(samples_to_show) >= 5:\n",
    "                break\n",
    "        inputs_for_tr = inp_tr.to(device, torch.float32)\n",
    "        inputs_for_rm = tr(coords, angles, inputs=inputs_for_tr)\n",
    "        rms_orig = net(inp_net.to(device, torch.float32))\n",
    "        rms_gen = net(inputs_for_rm)\n",
    "\n",
    "        show_samplesv2({'targ' : targ_net, 'input_orig': inp_net,'rms_orig': rms_orig, 'inputs_for_rm': inputs_for_rm,  'rms_gen' : rms_gen}, titles=titles, batch_ids=samples_to_show)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for conversion between log and linear scale, coverage scores for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### values from our dataset, for conversion between [0,1] grayscale used by networks and dBm\n",
    "PL_min = -127\n",
    "PL_max = -50\n",
    "\n",
    "def gray_dBm(t, PL_min, PL_max):\n",
    "        return t * (PL_max - PL_min) + PL_min\n",
    "\n",
    "def dBm_gray(dBm, PL_min, PL_max):\n",
    "    return (dBm - PL_min) / (PL_max - PL_min)\n",
    "\n",
    "### functions used to calculate the coverage score\n",
    "def boltzman(t, a):\n",
    "    '''boltzman operator, approximates minimum of t in a smooth way for a < 0'''\n",
    "    m = np.nanmax((a * t).detach().cpu().numpy())\n",
    "    num = torch.nansum(t * torch.exp(a * t - m))\n",
    "    denom = torch.nansum(torch.exp(a * t - m))\n",
    "    return num / denom\n",
    "\n",
    "def sum_lin(rms_gray, PL_min, PL_max, tx_power_dBm=0, clip=True):\n",
    "    '''Sums up all received powers from rms_gray and converts back to gray-scale. Using logsumexp we can avoid numerical problems due to very small numbers in linear scale'''\n",
    "    ### store the positions where the CNN predicted the minimum possible path loss it has seen during training, set to 0W / 0mW later in summation\n",
    "    mask = (rms_gray <= 0)\n",
    "    rms_dBm = gray_dBm(rms_gray, PL_max=PL_max, PL_min=PL_min) + tx_power_dBm\n",
    "    sum_dBm = 10 / np.log(10) * torch.logsumexp(torch.where(mask, -torch.inf, rms_dBm * np.log(10) / 10), dim=0, keepdim=True)\n",
    "    if clip:\n",
    "        return torch.clip(dBm_gray(sum_dBm, PL_max=PL_max, PL_min=PL_min), 0, 1)\n",
    "    else:\n",
    "        return dBm_gray(sum_dBm, PL_max=PL_max, PL_min=PL_min)\n",
    "\n",
    "def get_min(sum_gray, target_area, PL_min, PL_max, a=None, verbose=False, title=None, smooth=False, q=None):\n",
    "    '''\n",
    "    Sums up all received powers from rms_gray and returns the minimum value of the resulting tensor in the target_area. \n",
    "    If a is not None, uses boltzman instead of the strict minimum. \n",
    "    Returned mininmum is in gray_scale.\n",
    "    '''\n",
    "    ### set all values outside the target area to the maximum received power for calculation of the\n",
    "    # sum_gray_max = torch.where(target_area, sum_gray, 1)\n",
    "    sum_gray = torch.where(target_area, sum_gray, torch.nan)\n",
    "\n",
    "    m_real = torch.tensor(np.nanmin(sum_gray.detach().cpu().numpy()), device=sum_gray.device, dtype=sum_gray.dtype) if q is None else torch.nanquantile(sum_gray, q=q)\n",
    "    m_smooth = boltzman(sum_gray, a) if smooth and a is not None else m_real.clone()\n",
    "    if a is not None and smooth:\n",
    "        m = boltzman(sum_gray, a)\n",
    "    else:\n",
    "        if q is None:\n",
    "            m = torch.tensor(np.nanmin(sum_gray.detach().cpu().numpy()), device=sum_gray.device, dtype=sum_gray.dtype)\n",
    "        else:\n",
    "            m = torch.nanquantile(sum_gray, q=q)\n",
    "    if verbose:\n",
    "        print(f'smooth score={m_smooth.item():.3f}, \\t in dBm: {gray_dBm(m, PL_max=PL_max, PL_min=PL_min).item():.3f} ',\n",
    "            f'\\treal score={m_real:.3f}, \\t in dBm: {gray_dBm(m_real, PL_max=PL_max, PL_min=PL_min).item():.3f} ')\n",
    "        show_samplesv2({'power sum in target area': torch.where(target_area, gray_dBm(sum_gray, PL_max=PL_max, PL_min=PL_min), torch.nan)}, titles=[title] if title is not None else None)\n",
    "        plt.show()\n",
    "\n",
    "    return m_smooth, m_real\n",
    "\n",
    "def smooth_threshold(a, thresh, steepness=10):\n",
    "    '''Smooth thresholding function, returns a value between 0 and 1.'''\n",
    "    return torch.sigmoid(steepness * (a - thresh))\n",
    "\n",
    "def count_above_thresh(sum_gray, target_area, thresh, steepness=None, verbose=False, title=None, smooth=False):\n",
    "    '''\n",
    "    Counts the number of pixels in sum_gray in the target area that are above thresh.\n",
    "    If steepness is not None, uses smooth_threshold instead of strict thresholding.\n",
    "    '''\n",
    "    \n",
    "    above_thresh_real = (sum_gray > thresh) \n",
    "    above_thresh_smooth = smooth_threshold(sum_gray, thresh, steepness) if steepness is not None and smooth else above_thresh_real.clone()\n",
    "\n",
    "    sum_above_thresh_real = torch.sum(above_thresh_real * target_area)\n",
    "    sum_above_thresh_smooth = torch.sum(above_thresh_smooth * target_area)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'above threshold smooth: {int(sum_above_thresh_smooth.item())} / {torch.sum(target_area).item()} pixels in target area, \\\n",
    "              without smoothing: {sum_above_thresh_real.item()} / {torch.sum(target_area).item()} pixels in target area')\n",
    "        \n",
    "        show_samplesv2({\n",
    "            'power sum/SINR' : sum_gray, \n",
    "            'above threshold smooth': above_thresh_smooth * target_area, \n",
    "            'above threshold' : above_thresh_real * target_area\n",
    "            }, titles=[title] if title is not None else None)\n",
    "        plt.show()\n",
    "    return sum_above_thresh_smooth, sum_above_thresh_real\n",
    "\n",
    "def SINR(rms_gray, noise_dBm, tx_power_dBm, PL_max, PL_min):\n",
    "    '''\n",
    "    Calculates the signal to interference plus noise ratio (SINR) in the target area of rms_gray, using the threshold thresh.\n",
    "    '''\n",
    "    power_dBm = gray_dBm(rms_gray, PL_max=PL_max, PL_min=PL_min) + tx_power_dBm\n",
    "    power_gray = dBm_gray(power_dBm, PL_max=PL_max, PL_min=PL_min)\n",
    "    sum_others_dBm = torch.zeros_like(rms_gray)\n",
    "    for i in range(rms_gray.shape[0]):\n",
    "        sum_others_dBm[i,:] = gray_dBm(sum_lin(torch.cat([power_gray[torch.arange(power_gray.shape[0]) != i,:], dBm_gray(torch.ones_like(rms_gray[:1,...]) * noise_dBm, PL_max=PL_max, PL_min=PL_min)]), clip=False, PL_max=PL_max, PL_min=PL_min), PL_max=PL_max, PL_min=PL_min)\n",
    "    diff_dB = power_dBm - sum_others_dBm\n",
    "    return torch.amax(diff_dB, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize angles using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD(angles, coords, inputs_for_tr, tr, net, target_area, PL_min, PL_max, max_iter=100, learning_rate=0.1, opt_fn=get_min, opt_fn_params={}, sum_fn=sum_lin, sum_fn_params={}, verbose_loop=True, output_dir=None, *args, **kwargs):\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "    angles = angles.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam([angles], lr=learning_rate, maximize=True)\n",
    "    best_angles = angles.clone().detach()\n",
    "    inputs_for_rm = tr(coords, angles, inputs=inputs_for_tr)\n",
    "    rms_gen = net(inputs_for_rm)\n",
    "    sum_gray = sum_fn(rms_gen, **sum_fn_params)\n",
    "    if output_dir is not None:\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        for i in range(rms_gen.shape[0]):\n",
    "            io.imsave(output_dir / f'rm_initial_{i}.png', np.clip(rms_gen[i,...].detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "        io.imsave(output_dir / f'sum_initial.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "        io.imsave(output_dir / f'sum_initial_0_50.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() / 50 * 255, 0, 255).astype(np.uint8))\n",
    "        io.imsave(output_dir / f'target_area.png', np.clip(target_area.squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))    \n",
    "        np.save(output_dir / f'sum_initial.npy', sum_gray.detach().cpu().numpy())\n",
    "        np.save(output_dir / f'target_area.npy', target_area.detach().cpu().numpy())\n",
    "    best_score_smooth, best_score_real = opt_fn(sum_gray, target_area, **opt_fn_params, verbose=True, title=f'initial angles')\n",
    "    best_score_smooth, best_score_real = best_score_smooth.item(), best_score_real.item()\n",
    "\n",
    "    show_samplesv2({'radio maps' :  torch.clip(gray_dBm(rms_gen, PL_max=PL_max, PL_min=PL_min), PL_min, PL_max).transpose(0,1),\n",
    "                    'sum' :  torch.where(target_area, gray_dBm(sum_gray, PL_min=PL_min, PL_max=PL_max), torch.nan)}, \n",
    "                    titles=['radio maps [dBm] inital angles'], filename=output_dir.with_name(f'{output_dir.name}_initial')if output_dir is not None else None,\n",
    "    )#vmin=PL_min, vmax=PL_max)\n",
    "    best_it = -1\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        if max_iter>10 and i % (max_iter//10) == 0:            \n",
    "            print(f'.', end='')\n",
    "        optimizer.zero_grad()\n",
    "        inputs_for_rm = tr(coords, angles, inputs=inputs_for_tr)\n",
    "        rms_gen = net(inputs_for_rm)\n",
    "        sum_gray = sum_fn(rms_gen, **sum_fn_params)\n",
    "        score_smooth, score_real = opt_fn(sum_gray, target_area, **opt_fn_params, verbose=(i % (max_iter//10) == 0 or i==max_iter-1) and verbose_loop, title=f'iter {i}')\n",
    "        score_smooth.backward()\n",
    "        optimizer.step()\n",
    "        if score_real > best_score_real:\n",
    "            best_score_real = score_real.item()\n",
    "            best_score_smooth = score_smooth.item()\n",
    "            best_angles = angles.clone().detach()\n",
    "            best_it = i\n",
    "            if verbose_loop:\n",
    "                print(f'iter {i}: score increased to {best_score_smooth:.3f} smooth, {best_score_real:.3f} real angles={best_angles.cpu().numpy().tolist()}')\n",
    "                if output_dir is not None:\n",
    "                    for i in range(rms_gen.shape[0]):\n",
    "                        io.imsave(output_dir / f'rm_final_{i}.png', np.clip(rms_gen[i,...].detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "                    io.imsave(output_dir / f'sum_final.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "                    io.imsave(output_dir / f'sum_final_0_50.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() / 50 * 255, 0, 255).astype(np.uint8))\n",
    "                    np.save(output_dir / f'sum_final.npy', sum_gray.detach().cpu().numpy())\n",
    "                show_samplesv2({'radio maps' :  torch.clip(gray_dBm(rms_gen, PL_max=PL_max, PL_min=PL_min), PL_min, PL_max).transpose(0,1), \n",
    "                            'sum' : torch.where(target_area, gray_dBm(sum_gray, PL_min=PL_min, PL_max=PL_max), torch.nan)}, titles=['radio maps [dBm] best angles'], \n",
    "                            filename=output_dir)#, vmin=PL_min, vmax=PL_max)\n",
    "    print(f'{best_it=}, \\t{best_score_smooth=:.3f} ({gray_dBm(best_score_smooth, PL_max=PL_max, PL_min=PL_min):.3f}dBm), \\t{best_score_real=:.3f} ({gray_dBm(best_score_real, PL_max=PL_max, PL_min=PL_min):.3f}dBm), \\t{best_angles.tolist()=}')            \n",
    "\n",
    "    return best_angles, best_score_smooth, best_score_real\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search(angles_orig, coords, inputs_for_tr, tr, net, target_area, PL_min, PL_max, device=torch.device('cuda'), max_iter=100, opt_fn=get_min, opt_fn_params={}, sum_fn=sum_lin, sum_fn_params={}, verbose_loop=True, output_dir=None, *args, **kwargs):\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "    with torch.no_grad():\n",
    "        best_angles = angles_orig.clone().detach()\n",
    "        best_it = -1\n",
    "\n",
    "        inputs_for_rm = tr(coords, angles_orig, inputs=inputs_for_tr)\n",
    "        rms_gen = net(inputs_for_rm)\n",
    "        sum_gray = sum_fn(rms_gen, **sum_fn_params)\n",
    "        if output_dir is not None:\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            for i in range(rms_gen.shape[0]):\n",
    "                io.imsave(output_dir / f'rm_initial_{i}.png', np.clip(rms_gen[i,...].detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "            io.imsave(output_dir / f'sum_initial.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "            io.imsave(output_dir / f'sum_initial_0_50.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() / 50 * 255, 0, 255).astype(np.uint8))\n",
    "            io.imsave(output_dir / f'target_area.png', np.clip(target_area.squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "            np.save(output_dir / f'sum_initial.npy', sum_gray.detach().cpu().numpy())\n",
    "            np.save(output_dir / f'target_area.npy', target_area.detach().cpu().numpy())\n",
    "        best_score_smooth, best_score_real = opt_fn(sum_gray, target_area, **opt_fn_params, verbose=True, title=f'initial angles')\n",
    "        best_score_smooth, best_score_real = best_score_smooth.item(), best_score_real.item()\n",
    "        show_samplesv2({'radio maps' : torch.clip(gray_dBm(rms_gen, PL_min=PL_min, PL_max=PL_max), PL_min, PL_max).transpose(0,1),\n",
    "                        'sum' :  torch.where(target_area, gray_dBm(sum_gray, PL_min=PL_min, PL_max=PL_max), torch.nan)}, \n",
    "                       titles=['radio maps [dBm] inital angles'], filename=output_dir.with_name(f'{output_dir.name}_initial')if output_dir is not None else None,\n",
    "        )#vmin=PL_min, vmax=PL_max)\n",
    "\n",
    "        for i in range(max_iter):\n",
    "            ### search in given phi+/-3pi/4, theta in [pi/2, pi]\n",
    "            phis = angles_orig[:,0] + 3/2 * torch.pi * (torch.rand(angles_orig.shape[0], dtype=torch.float32, device=device) - 0.5)\n",
    "            thetas = torch.pi / 2 + torch.pi / 2 * torch.rand(angles_orig.shape[0], dtype=torch.float32, device=device)\n",
    "            angles = torch.stack([phis, thetas], dim=-1)\n",
    "            \n",
    "            inputs_for_rm = tr(coords, angles, inputs=inputs_for_tr)\n",
    "            rms_gen = net(inputs_for_rm)\n",
    "            sum_gray = sum_fn(rms_gen, **sum_fn_params)\n",
    "            score_smooth, score_real = opt_fn(sum_gray, target_area, **opt_fn_params)\n",
    "\n",
    "\n",
    "            if score_real > best_score_real:\n",
    "                best_score_real = score_real.item()\n",
    "                best_score_smooth = score_smooth.item()\n",
    "                best_angles = angles.clone().detach()\n",
    "                best_it = i\n",
    "                if verbose_loop:\n",
    "                    print(f'iter {i}: score increased to {best_score_smooth:.3f} smooth, {best_score_real:.3f} real angles={best_angles.cpu().numpy().tolist()}')\n",
    "                    if output_dir is not None:\n",
    "                        for i in range(rms_gen.shape[0]):\n",
    "                            io.imsave(output_dir / f'rm_final_{i}.png', np.clip(rms_gen[i,...].detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "                        io.imsave(output_dir / f'sum_final.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() * 255, 0, 255).astype(np.uint8))\n",
    "                        io.imsave(output_dir / f'sum_final_0_50.png', np.clip(torch.where(target_area, sum_gray, 0).squeeze().detach().cpu().numpy() / 50 * 255, 0, 255).astype(np.uint8))\n",
    "                        np.save(output_dir / f'sum_final.npy', sum_gray.detach().cpu().numpy())\n",
    "                    show_samplesv2({'radio maps' :  torch.clip(gray_dBm(rms_gen, PL_max=PL_max, PL_min=PL_min), PL_min, PL_max).transpose(0,1), \n",
    "                                'sum' : torch.where(target_area, gray_dBm(sum_gray, PL_min=PL_min, PL_max=PL_max), torch.nan)}, titles=['radio maps [dBm] best angles'], \n",
    "                                filename=output_dir)#, vmin=PL_min, vmax=PL_max)\n",
    "\n",
    "                \n",
    "        # if verbose_loop:\n",
    "        print(f'{best_it=}, \\t{best_score_smooth=:.3f} ({gray_dBm(best_score_smooth, PL_max=PL_max, PL_min=PL_min):.3f}dBm), \\t{best_score_real=:.3f} ({gray_dBm(best_score_real, PL_max=PL_max, PL_min=PL_min):.3f}dBm), \\t{best_angles.tolist()=}')            \n",
    "        return best_angles, best_score_smooth, best_score_real\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define the dataset and loader to obtain maps and tx coords\n",
    "batch_size = 1\n",
    "seed = 1\n",
    "\n",
    "dm2 = LitRM_directional(tx_one_hot=False, ndsms=True, ant_gain_floor=False, ant_gain_top=False, ndsm_all=True, img=True, augmentation=False, batch_size=batch_size, shuffle=False)\n",
    "dm2.setup('test')\n",
    "loader = dm2.test_dataloader(shuffle=True)#, seed=seed if not already_set_seed else None)\n",
    "iterator = iter(loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a Predefined Scenario\n",
    "- We define the two scenarios used in the paper.\n",
    "- Alternatively, one can iterate through the dataloader from the previous cell to find an interesting map and define the target_area etc similarly to below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scenario(scenario : int, tx_power_dBm, PL_max, PL_min, smooth, a=-5):\n",
    "    if scenario == 1:\n",
    "        i, j, s = 3815, 58105, 'ur'\n",
    "        tx_ids = [0, 1, 3]\n",
    "        rectangles = [\n",
    "            [20, -20, 20, -20]\n",
    "        ]\n",
    "\n",
    "        ### summation of all powers or SINR\n",
    "        sum_fn = sum_lin\n",
    "        sum_fn_params = {'tx_power_dBm' : tx_power_dBm, 'clip' : True, 'PL_max' : PL_max, 'PL_min' : PL_min}\n",
    "\n",
    "        ### choose optimization target, either min over target area or counting locations with a value above some threshold\n",
    "        opt_fn = get_min\n",
    "        opt_fn_params = {'a' : a if smooth else None, 'PL_max' : PL_max, 'PL_min' : PL_min, 'smooth' : smooth, 'q' : 0.1}\n",
    "\n",
    "\n",
    "    elif scenario==2:\n",
    "        i, j, s = 3860, 58140, 'lr'\n",
    "        tx_ids = [0, 2, 3]\n",
    "        # streets\n",
    "        rectangles = [\n",
    "            [-80, -50, 0, -40],\n",
    "            [80, -1, 55, 90],\n",
    "            [0, -1, 175, 220]\n",
    "        ]\n",
    "\n",
    "        sum_fn = SINR\n",
    "        sum_fn_params = {'noise_dBm' : -104, 'tx_power_dBm' : tx_power_dBm, 'PL_max' : PL_max, 'PL_min' : PL_min}\n",
    "\n",
    "        opt_fn = count_above_thresh\n",
    "        thresh = 20\n",
    "        opt_fn_params = {'thresh': thresh, 'steepness': 0.1 if smooth else None, 'smooth' : smooth}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f'{scenario=} not defined. But you can choose a map and set all parameters yourself.')\n",
    "    \n",
    "    return i, j, s, tx_ids, rectangles, sum_fn, sum_fn_params, opt_fn, opt_fn_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Choose a scenario and parameters\n",
    "scenario = 2\n",
    "tx_power_dBm = 23\n",
    "a = -5 # steepness for smooth thresholding\n",
    "output_dir = Path(f'./logs_opt/{scenario=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize the scenario\n",
    "i, j, s, tx_ids, rectangles, sum_fn, sum_fn_params, opt_fn, opt_fn_params = get_scenario(scenario=scenario, tx_power_dBm=tx_power_dBm, PL_min=PL_min, PL_max=PL_max, smooth=True, a=a)\n",
    "### prepare data\n",
    "inp, _, _ = dm2.test_set.__getsample__((i,j,s,'0'))\n",
    "ndsm_build, ndsm_veg = inp[0,:,:], inp[1,:,:]\n",
    "img_rgb = inp[-4:-1,...]\n",
    "sample_id = [[i], [j], [s], [0]]\n",
    "target_area = torch.zeros_like(ndsm_build)\n",
    "for x_min, x_max, y_min, y_max in rectangles:\n",
    "    target_area[x_min:x_max, y_min:y_max] = 1\n",
    "target_area[ndsm_build > 0] = 0\n",
    "\n",
    "coords, angles_orig = get_coords_angles(sample_id, 0, tx_ant_dir=tx_ant_dir, tx_ant_file_name=tx_ant_file_name, coords_requires_grad=False, angles_requires_grad=True, tx_ids=tx_ids)\n",
    "inputs_for_tr = inp[2:,:,:].to(device, torch.float32).repeat(coords.shape[0], 1, 1, 1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(torch.stack([ndsm_build, target_area, torch.zeros_like(target_area)], dim=-1))\n",
    "plt.scatter(coords[:,1].cpu(), coords[:,0].cpu(), s=20, c='b')\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(img_rgb.permute(1, 2, 0))\n",
    "plt.scatter(coords[:,1].cpu(), coords[:,0].cpu(), s=20, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Optimization with Gradient Descent and Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "### optimization method and params\n",
    "opt_method1 = random_search\n",
    "opt_method2 = GD\n",
    "\n",
    "learning_rate = 0.1\n",
    "max_iter = 500\n",
    "\n",
    "ta = target_area.to(device, torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run method 1\n",
    "i, j, s, tx_ids, rectangles, sum_fn, sum_fn_params, opt_fn, opt_fn_params = get_scenario(scenario=scenario, tx_power_dBm=tx_power_dBm, PL_min=PL_min, PL_max=PL_max, smooth=opt_method1==GD, a=a)\n",
    "print(f'optimization method1 {opt_method1.__name__}, {max_iter=}, {learning_rate=}, {opt_fn=}, {opt_fn_params=}, {sum_fn=}')\n",
    "\n",
    "s = time.time()\n",
    "angles_calc, score_smooth, score_real = opt_method1(angles_orig, coords, inputs_for_tr, tr, net, ta, PL_min=PL_min, PL_max=PL_max, max_iter=max_iter, learning_rate=learning_rate, opt_fn=opt_fn, opt_fn_params=opt_fn_params, sum_fn=sum_fn, sum_fn_params=sum_fn_params, output_dir=output_dir / opt_method1.__name__)\n",
    "\n",
    "print(f'{time.time() - s:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run method2\n",
    "i, j, s, tx_ids, rectangles, sum_fn, sum_fn_params, opt_fn, opt_fn_params = get_scenario(scenario=scenario, tx_power_dBm=tx_power_dBm, PL_min=PL_min, PL_max=PL_max, smooth=opt_method2==GD, a=a)\n",
    "print(f'optimization method2 {opt_method2.__name__}, {max_iter=}, {learning_rate=}, {opt_fn=}, {opt_fn_params=}, {sum_fn=}')\n",
    "\n",
    "s = time.time()\n",
    "angles_calc, score_smooth, score_real = opt_method2(angles_orig, coords, inputs_for_tr, tr, net, ta, PL_min=PL_min, PL_max=PL_max, max_iter=max_iter, learning_rate=learning_rate, opt_fn=opt_fn, opt_fn_params=opt_fn_params, sum_fn=sum_fn, sum_fn_params=sum_fn_params, output_dir=output_dir / opt_method2.__name__)\n",
    "\n",
    "print(f'{time.time() - s:.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE REMOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_to_color(filename : Path, vmin : float, vmax : float):\n",
    "    if filename.stem.endswith('_color'):\n",
    "        return\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(1,1)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    arr = io.imread(filename)\n",
    "    plt.imshow(arr, vmin=vmin, vmax=vmax)\n",
    "    # plt.axis('off')\n",
    "    # plt.box(False)\n",
    "    plt.savefig(filename.with_stem(f'{filename.stem}_color'),dpi=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for png_file in output_dir.rglob(\"*.png\"):\n",
    "    gray_to_color(png_file, vmin=0, vmax=255)\n",
    "    print(png_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
